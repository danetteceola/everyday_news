## Context

Everyday News系统需要从5个主流社交平台（Twitter、YouTube、TikTok、微博、抖音）采集热门新闻数据。每个平台有不同的数据结构、API限制和反爬策略。当前项目处于规划阶段，已有详细的数据采集设计文档（docs/01-data-collection.md），但尚未开始编码实现。

数据采集面临的主要挑战包括：平台反爬机制、数据格式不统一、API调用限制、网络稳定性等。需要建立一个可靠、可扩展、易于维护的数据采集系统。

## Goals / Non-Goals

**Goals:**
1. 实现5个平台的数据采集功能，支持定时自动采集
2. 建立统一的数据模型，标准化不同平台的数据格式
3. 实现有效的反爬对策，确保采集稳定性和持续性
4. 提供数据清洗和去重功能，保证数据质量
5. 支持灵活的采集任务配置和管理

**Non-Goals:**
1. 不实现实时数据流采集（定时批量采集足够）
2. 不处理需要登录的私有内容（只采集公开热门内容）
3. 不实现复杂的分布式爬虫（单机顺序采集足够）
4. 不绕过平台明确的访问限制（遵守robots.txt和API限制）

## Decisions

### 1. 采集工具选择
**选择**: 使用MCP Browser作为主要采集工具，辅以官方API
**理由**:
- MCP Browser提供了强大的浏览器自动化能力，可以处理JavaScript渲染的页面
- 支持模拟真实用户行为，降低被反爬系统检测的风险
- 可以处理复杂的登录和交互场景（如需要）
- 官方API提供更稳定和规范的数据访问（如可用）
**替代方案考虑**:
- 考虑过使用Playwright直接控制浏览器，但MCP Browser提供了更好的抽象和工具集成
- 考虑过使用纯HTTP请求库（如axios），但无法处理JavaScript渲染的内容

### 2. 数据模型设计
**选择**: 统一的NewsItem接口，包含平台特定扩展字段
**理由**:
- 提供标准化的数据结构，便于后续处理和存储
- 保留平台特定字段的灵活性，通过扩展字段支持
- 类型安全的TypeScript接口，提高代码质量
**替代方案考虑**:
- 考虑过完全统一的数据模型，但不同平台数据差异较大，难以完全统一
- 考虑过平台完全独立的数据模型，但会增加后续处理的复杂度

### 3. 反爬策略设计
**选择**: 分层反爬对策系统
**理由**:
- 随机延迟请求：避免请求频率过高被检测
- 错误重试机制：自动处理临时网络问题
- 代理轮换：IP被封时自动切换代理
- 降级方案：API失败时降级到网页采集，网页采集失败时使用缓存
**替代方案考虑**:
- 考虑过使用商业反爬服务，但成本较高且增加外部依赖
- 考虑过更复杂的反爬策略（如浏览器指纹模拟），但当前需求复杂度不高

### 4. 采集任务调度
**选择**: 基于平台优先级和频率的任务调度
**理由**:
- Twitter和微博：高优先级，每小时采集
- YouTube：高优先级，每6小时采集
- TikTok和抖音：中优先级，每日2次采集
- 支持动态调整采集频率和优先级
**替代方案考虑**:
- 考虑过固定时间表调度，但不够灵活
- 考虑过基于数据新鲜度的动态调度，但实现复杂度较高

### 5. 数据清洗和去重
**选择**: 基于内容和URL的多维度去重
**理由**:
- URL去重：相同URL的内容视为重复
- 内容相似度去重：使用文本相似度算法识别相似内容
- 时间窗口去重：同一内容在不同时间出现视为更新而非重复
**替代方案考虑**:
- 考虑过使用机器学习进行内容去重，但实现复杂且需要训练数据
- 考虑过简单的关键词匹配去重，但准确率较低

## Risks / Trade-offs

### 风险1: 平台反爬升级
- **风险**: 平台更新反爬策略导致采集失败
- **缓解**: 快速迭代采集脚本，多采集策略备选，监控采集成功率

### 风险2: 数据不完整
- **风险**: 采集的数据缺失关键字段或数量不足
- **缓解**: 多源验证，数据质量检查，采集失败重试

### 风险3: IP被封
- **风险**: 采集频率过高导致IP被平台封禁
- **缓解**: 代理轮换，请求频率控制，遵守平台访问限制

### 风险4: 法律合规风险
- **风险**: 采集行为可能违反平台服务条款或相关法律
- **缓解**: 只采集公开数据，遵守robots.txt，设置合理的采集频率

### 权衡: 采集频率 vs 数据新鲜度
- **选择**: 平衡采集频率和数据新鲜度，避免过度采集
- **理由**: 新闻数据有一定时效性，但过度采集会增加反爬风险
- **代价**: 可能错过一些快速变化的趋势

### 权衡: 数据完整性 vs 采集性能
- **选择**: 优先保证数据完整性，适当牺牲采集性能
- **理由**: 数据质量对后续分析和总结更重要
- **代价**: 采集时间可能较长，需要更多资源

## Migration Plan

### 部署步骤
1. **环境准备**: 安装Node.js、MCP Browser、配置代理（如需要）
2. **平台采集器开发**: 按优先级逐个实现平台采集器
3. **反爬系统集成**: 集成反爬对策到各采集器
4. **数据清洗测试**: 测试数据清洗和去重功能
5. **任务调度集成**: 集成到系统调度器中
6. **监控和优化**: 监控采集性能，优化采集策略

### 回滚策略
- 每个平台采集器独立部署和测试
- 保留旧版本采集脚本
- 关键采集操作记录详细日志，便于问题排查

## Open Questions

1. **代理服务选择**: 是否需要商业代理服务？使用免费代理是否足够？
2. **数据存储格式**: 采集的原始数据是否需要完整保存？保存期限多长？
3. **错误处理策略**: 采集失败时是否应该继续采集其他平台？还是停止整个采集任务？
4. **监控指标**: 需要监控哪些关键指标来评估采集系统健康状态？